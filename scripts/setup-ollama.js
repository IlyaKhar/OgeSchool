/**
 * –°–∫—Ä–∏–ø—Ç –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ –ø—Ä–æ–≤–µ—Ä–∫–∏ Ollama
 */

require('dotenv').config();
const axios = require('axios');
const fs = require('fs');
const path = require('path');

const OLLAMA_BASE_URL = process.env.OLLAMA_BASE_URL || 'http://localhost:11434';
const MODEL_NAME = process.env.OLLAMA_MODEL || 'llama3.2';

async function checkOllama() {
  try {
    console.log('üîç –ü—Ä–æ–≤–µ—Ä—è—é Ollama...');
    const response = await axios.get(`${OLLAMA_BASE_URL}/api/tags`, {
      timeout: 2000
    });
    
    if (response.status === 200) {
      console.log('‚úÖ Ollama –∑–∞–ø—É—â–µ–Ω–∞');
      const models = response.data.models || [];
      console.log(`üì¶ –£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –º–æ–¥–µ–ª–µ–π: ${models.length}`);
      
      const hasModel = models.some(m => m.name.includes(MODEL_NAME));
      if (hasModel) {
        console.log(`‚úÖ –ú–æ–¥–µ–ª—å ${MODEL_NAME} –Ω–∞–π–¥–µ–Ω–∞`);
        return true;
      } else {
        console.log(`‚ö†Ô∏è –ú–æ–¥–µ–ª—å ${MODEL_NAME} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞`);
        console.log(`üí° –ó–∞–ø—É—Å—Ç–∏: ollama pull ${MODEL_NAME}`);
        return false;
      }
    }
  } catch (error) {
    console.log('‚ùå Ollama –Ω–µ –∑–∞–ø—É—â–µ–Ω–∞');
    console.log('üí° –£—Å—Ç–∞–Ω–æ–≤–∏ Ollama: https://ollama.ai');
    console.log('üí° –ó–∞–ø—É—Å—Ç–∏: ollama serve');
    return false;
  }
}

async function pullModel() {
  try {
    console.log(`üì• –°–∫–∞—á–∏–≤–∞—é –º–æ–¥–µ–ª—å ${MODEL_NAME}...`);
    const response = await axios.post(
      `${OLLAMA_BASE_URL}/api/pull`,
      { name: MODEL_NAME, stream: false },
      { timeout: 300000 } // 5 –º–∏–Ω—É—Ç
    );
    console.log('‚úÖ –ú–æ–¥–µ–ª—å —Å–∫–∞—á–∞–Ω–∞');
    return true;
  } catch (error) {
    console.error('‚ùå –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏:', error.message);
    return false;
  }
}

async function testModel() {
  try {
    console.log('üß™ –¢–µ—Å—Ç–∏—Ä—É—é –º–æ–¥–µ–ª—å...');
    const response = await axios.post(
      `${OLLAMA_BASE_URL}/api/chat`,
      {
        model: MODEL_NAME,
        messages: [
          { role: 'user', content: '–ü—Ä–∏–≤–µ—Ç! –û—Ç–≤–µ—Ç—å –æ–¥–Ω–∏–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º.' }
        ],
        stream: false
      },
      { timeout: 30000 }
    );
    
    if (response.data.message?.content) {
      console.log('‚úÖ –ú–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç!');
      console.log(`üìù –û—Ç–≤–µ—Ç: ${response.data.message.content.substring(0, 100)}...`);
      return true;
    }
  } catch (error) {
    console.error('‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:', error.message);
    return false;
  }
}

async function main() {
  console.log('üöÄ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ Ollama –¥–ª—è OGE Platform\n');
  
  const isRunning = await checkOllama();
  if (!isRunning) {
    console.log('\n‚ùå Ollama –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞. –°–ª–µ–¥—É–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º –≤—ã—à–µ.');
    process.exit(1);
  }
  
  const needsModel = !(await checkOllama());
  if (needsModel) {
    const pulled = await pullModel();
    if (!pulled) {
      process.exit(1);
    }
  }
  
  const works = await testModel();
  if (works) {
    console.log('\n‚úÖ Ollama –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é!');
    console.log('üí° –£–±–µ–¥–∏—Å—å —á—Ç–æ –≤ .env —É–∫–∞–∑–∞–Ω–æ:');
    console.log('   AI_PROVIDER=ollama');
    console.log(`   OLLAMA_MODEL=${MODEL_NAME}`);
  } else {
    console.log('\n‚ùå –ú–æ–¥–µ–ª—å –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç. –ü—Ä–æ–≤–µ—Ä—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏.');
    process.exit(1);
  }
}

main().catch(console.error);

